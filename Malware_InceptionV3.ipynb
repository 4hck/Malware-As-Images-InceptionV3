{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exciting-roman",
   "metadata": {},
   "source": [
    "# Malware As Images \n",
    "## Malware Classification Using InceptionV3 CNN Model\n",
    "by Aaron Aranda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-fight",
   "metadata": {},
   "source": [
    "### Thanks to...\n",
    "* Matthew Fields \n",
    "   - https://github.com/fieldsfieldsfields\n",
    "   - https://www.kaggle.com/matthewfields/malware-as-images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import Model \n",
    "from tensorflow.keras.optimizers import RMSprop \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from numba import cuda \n",
    "import datetime\n",
    "\n",
    "# Plotting\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-sunday",
   "metadata": {},
   "source": [
    "## Hardware Configuration\n",
    "* GPU: Nvidia RTX 2080 Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very necessary, this solved a lot of issues with GPU usage\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# Allows efficient GPU memory allocation\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "if gpu:\n",
    "    print(\"GPU is available\")\n",
    "    tf.device('/GPU:0')\n",
    "else:\n",
    "    print(\"GPU NOT available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up working directories\n",
    "benign_path = Path(\"working_lanczos_all/data/benign\")\n",
    "benign_path.mkdir(parents=True, exist_ok=True)\n",
    "malicious_path = Path(\"working_lanczos_all/data/malicious\")\n",
    "malicious_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "Classes = [\"benign\", \"malicious\"]\n",
    "data_path = \"working_lanczos_all/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r ./data/benign/lanczos_*/* {benign_path}/\n",
    "!cp -r ./data/malicious/lanczos_*/* {malicious_path}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-integration",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(data_path):\n",
    "    train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_path,\n",
    "        labels=\"inferred\",\n",
    "        seed=123,\n",
    "        shuffle=True,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        image_size=(299,299),\n",
    "        batch_size=8,\n",
    "        color_mode='rgb'\n",
    "    )\n",
    "\n",
    "    validation_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_path,\n",
    "        labels=\"inferred\",\n",
    "        seed=123,\n",
    "        shuffle=True,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        image_size=(299,299),\n",
    "        batch_size=8,\n",
    "        color_mode='rgb'\n",
    "        \n",
    "    )\n",
    "    return train_data, validation_data\n",
    "\n",
    "train, validation = train_valid_split(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a test set\n",
    "val_batches = tf.data.experimental.cardinality(validation)\n",
    "test_set = validation.take(val_batches // 3)\n",
    "validation = validation.skip(val_batches // 3)\n",
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"pe_imgs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create InceptionV3 instance, using ImageNet weights\n",
    "inception = InceptionV3(include_top=False, weights='imagenet')\n",
    "\n",
    "# Freeze model layers\n",
    "inception.trainable = False\n",
    "inception.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-weight",
   "metadata": {},
   "source": [
    "## Customizing InceptionV3 Model for Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set InceptionV3 input shape\n",
    "inputs = tf.keras.Input(shape=(299,299,3))\n",
    "\n",
    "x = inception(inputs, training=False)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Use a dropout layer to reduce overfitting (randomly sets inputs to 0)\n",
    "x = layers.Dropout(0.2)(x)                                                 \n",
    "\n",
    "# Predictions are the last layer based on 2 classes\n",
    "outputs = layers.Dense(1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile \n",
    "learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now look at customized InceptionV3 + transfer learning layers\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='inceptionv3_model.png', show_shapes=False, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a callback to stop training when 99% accuracy is reached.\n",
    "class callback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') >= 0.99 :\n",
    "            print(\"99% Accuracy reached, training stopped.\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-average",
   "metadata": {},
   "source": [
    "## Training InceptionV3 with Transfer Learning (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up TensorBoard logging\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the data before training, just to get an idea of pre-trained InceptionV3's performance.\n",
    "loss, accuracy = model.evaluate(validation)\n",
    "print(\"initial loss: {:.2f}\".format(loss))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "my_callback = callback()\n",
    "epochs=10\n",
    "malware_inception = model.fit(train,\n",
    "                              validation_data=validation,\n",
    "                              epochs=epochs,\n",
    "                              verbose=1,\n",
    "                              shuffle=False,\n",
    "                              callbacks=[my_callback, tensorboard_callback])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = malware_inception.history['accuracy']\n",
    "validation_accuracy = malware_inception.history['val_accuracy']\n",
    "\n",
    "loss = malware_inception.history['loss']\n",
    "validation_loss = malware_inception.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, validation_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open TensorBoard for further evaluation on training\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-tucson",
   "metadata": {},
   "source": [
    "## Training InceptionV3 Model (Fine Tuning, Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfreeze top layers\n",
    "inception.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of layers in InceptionV3: \", len(inception.layers))\n",
    "# Where to fine tune model from\n",
    "fine_tune_from = 100\n",
    "\n",
    "#Freeze all layers before this\n",
    "for layer in inception.layers[:fine_tune_from]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(lr=learning_rate/10),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the number of trainable params \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training\n",
    "fine_tune_epochs = 10\n",
    "total_epochs = epochs + fine_tune_epochs\n",
    "\n",
    "fine_tune_malware_inception= model.fit(train,\n",
    "                                       validation_data=validation,\n",
    "                                       epochs=total_epochs,\n",
    "                                       initial_epoch=malware_inception.epoch[-1],\n",
    "                                       verbose=1,\n",
    "                                       callbacks=[my_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-immune",
   "metadata": {},
   "source": [
    "## Evaluation of Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to performance visual\n",
    "accuracy += fine_tune_malware_inception.history['accuracy']\n",
    "validation_accuracy += fine_tune_malware_inception.history['val_accuracy']\n",
    "\n",
    "loss += fine_tune_malware_inception.history['loss']\n",
    "validation_loss += fine_tune_malware_inception.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(accuracy, label='Training Accuracy')\n",
    "plt.plot(validation_accuracy, label='Validation Accuracy')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot([epochs-1,epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([epochs-1,epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "plt.savefig(\"fine_tune_accuracy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-device",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import Session\n",
    "#Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_set.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "print(test_set.list_files(file_pattern='*.png'))\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(8):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "    plt.title(Classes[predictions[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-default",
   "metadata": {},
   "source": [
    "# Visualizing Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-flexibility",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "malicious_img_path = \"data/malicious/nearest_1200/Alina.3.4.B_nearest_1200_.png\"\n",
    "\n",
    "conv_layer = model.layers[1]\n",
    "for layers in model.layers:\n",
    "    if 'conv' in layers.name and layers.trainable:\n",
    "        conv_layer = layers\n",
    "        \n",
    "        \n",
    "successive_outputs = conv_layer.output\n",
    "visualization = Model(inputs = model.input, outputs = successive_outputs)\n",
    "\n",
    "img = load_img(malicious_img_path, target_size=(299,299))\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "x /- 255.0\n",
    "\n",
    "successive_feature_maps = visualization.predict(x)\n",
    "conv_name = conv_layer.name\n",
    "\n",
    "\"\"\"\n",
    "DISPLAY\n",
    "\"\"\"\n",
    "\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "    print(feature_map.shape)\n",
    "    if len(feature_map.shape) == 4:\n",
    "        n_features = feature_map.shape[-1]\n",
    "        size = feature_map.shape[1]\n",
    "        \n",
    "        display_grid = np.zeros((size, size * n_features))\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            x = feature_map[0, :, :, i]\n",
    "            x -= x.mean()\n",
    "            x /= x.std()\n",
    "            x *= 64\n",
    "            x += 128\n",
    "            x = np.clip(x, 0, 255).astype('uint8')\n",
    "            display_grid[:, i * size : (i + 1) * size] = x\n",
    "            \n",
    "            scale = 20. / n_features\n",
    "            plt.figure(figsize=(scale * n_features, scale))\n",
    "            plt.title(layer_name)\n",
    "            plt.grid(False)\n",
    "            plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "malicious_path = \"data/malicious/nearest_1200/Alina.3.4.B_nearest_1200_.png\"\n",
    "img = load_img(malicious_path, target_size=(299, 299))\n",
    "img_array = img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) \n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(Classes[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_malware_inception.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/malware_inceptionv3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-n-gpu] *",
   "language": "python",
   "name": "conda-env-tf-n-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
